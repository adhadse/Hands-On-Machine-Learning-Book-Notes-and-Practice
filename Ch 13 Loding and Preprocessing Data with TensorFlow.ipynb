{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch 13 Loding and Preprocessing Data with TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNDfQs3T8f+MZOXOAnk1P5s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f1de6cc217f4d06a5cf78d4f0901867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ee2696246fcc40de8e5835fd4c39c21b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0458f79b63804cedb85fc7c39382bcf8",
              "IPY_MODEL_43c666d82e094e8ca5e92f516499efa3"
            ]
          }
        },
        "ee2696246fcc40de8e5835fd4c39c21b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0458f79b63804cedb85fc7c39382bcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b36b132663d4d76ad156c8a0ce6cfd0",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14922ad8d602457ca598d8115b10e72a"
          }
        },
        "43c666d82e094e8ca5e92f516499efa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bfc22d6ba6d647169b8a91f2ac8eeb62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00,  6.02 file/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f7174645c774868b0452809fba9f511"
          }
        },
        "6b36b132663d4d76ad156c8a0ce6cfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14922ad8d602457ca598d8115b10e72a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfc22d6ba6d647169b8a91f2ac8eeb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f7174645c774868b0452809fba9f511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adhadse/colab_repo/blob/master/homl/Ch%2013%20Loding%20and%20Preprocessing%20Data%20with%20TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKg1C8a0sFiO"
      },
      "source": [
        "# Chapter 13: Loading and Preprocessing Data with TensorFlow\n",
        "This work is partialy combined text and code from the book [Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) and is only supposed to be used as reference and recommended to follow along with a copy of the Book puchased.\n",
        "\n",
        "---\n",
        "Deep Learning often requires which can not fit into Memory.\n",
        "\n",
        "TensorFlow Data API: makes it very easy to point to data souce on the disk, and how to get transform it. TensorFlow takes care of all the implementation details, such as multithreading, queuing, batching, and prefetching. \n",
        "\n",
        "The Data API has also support for reading SQL databases, TensorFlow's TFRecord format, which is an efficient binary format based on Protocol Buffers. Many open source extensions are available to read from various other data sources.\n",
        "\n",
        "We also requires preprocessing this Data before fedding it to the ML model. \n",
        "\n",
        "In this chapter focus will be on the Data API, TFRecord formaat and how to create a custom Preprocessing layer using Keras. At the end we will also take a look at few related project:\n",
        "\n",
        "- *TF Transform (tf.Transform)*\n",
        "- *TF Datasets (TFDS)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feUI1AjOikEk"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-RTLt8ogBDq"
      },
      "source": [
        "# The Data API\n",
        "The whole Data AP revolves around the concept of a ***Dataset***: <mark>Represent a sequence of data items, which you usually will use to read data from the disk.</mark>\n",
        "\n",
        "For now we create a dataset only on RAM, using\n",
        "\n",
        "**`tf.data.Dataset.from_tensor_slices()`**: \n",
        "\n",
        "which takes tensor and creates a `tf.data.Dataset` whose elements are all the slices of X (along the first dimension). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65MR61inhwP2",
        "outputId": "10880a3d-a88b-4d50-cfd7-722bd8075553"
      },
      "source": [
        "X = tf.range(10) # any data tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ngxMeIhj2sk"
      },
      "source": [
        "Iterating over this dataset is also simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQL18FwHiq8n",
        "outputId": "37e32321-4494-485b-f426-8c93e9ebeab0"
      },
      "source": [
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_c-9-DCkDc9"
      },
      "source": [
        "## Chaining Transformations\n",
        "Once we have datasets, we can apply any type of transformations and even chain them.\n",
        "\n",
        "To transform we neet to call its transformation methods, each of which returns a new dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAwjPgnUjyEw",
        "outputId": "cdaf8e77-0b74-4764-ef25-f049fbcc63e0"
      },
      "source": [
        "# drop_remainder drops the batch which it can accomodate for\n",
        "# exact same shape as specified\n",
        "dataset = dataset.repeat(3).batch(7, drop_remainder=True)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXuL-fXimFM7"
      },
      "source": [
        ">ðŸŸ  This dataset methods DO NOT modify the datasets, they create a new ones.\n",
        "\n",
        "**map()**: applies transformation to each item.\n",
        "\n",
        "We can also use lambda to apply transformations to the datset using the `map()` method. This is where most of work will happen related to preprocessing, the funciton called here must be convertible to TF function.\n",
        "\n",
        "It can quite become intensive, so setting the `num_parallel_calls` argument can speed up by distributing the workload on multiple threads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTwQzwQ6jt8d",
        "outputId": "47369351-8afe-485a-f5c0-e4b8b73d4e43"
      },
      "source": [
        "dataset = dataset.map(lambda x: x *2)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5tIGAlCqqqu"
      },
      "source": [
        "**`apply()`**: Applies transformation to the whole dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7y04jzjmseB",
        "outputId": "9b6ebc83-d724-4553-b4a9-ad2fad177aa2"
      },
      "source": [
        "dataset = dataset.apply(tf.data.experimental.unbatch())\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-d681510aff78>:1: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.unbatch()`.\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(10, shape=(), dtype=int32)\n",
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "tf.Tensor(14, shape=(), dtype=int32)\n",
            "tf.Tensor(16, shape=(), dtype=int32)\n",
            "tf.Tensor(18, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(10, shape=(), dtype=int32)\n",
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "tf.Tensor(14, shape=(), dtype=int32)\n",
            "tf.Tensor(16, shape=(), dtype=int32)\n",
            "tf.Tensor(18, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(10, shape=(), dtype=int32)\n",
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "tf.Tensor(14, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-P-bRvRrS8p"
      },
      "source": [
        "**`filter()`**: This can be used to filter the datset, based on a condition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NV1Co9zrPrA",
        "outputId": "c9d5f315-2a5a-4e3c-bf7a-31c2c8f626f0"
      },
      "source": [
        "dataset = dataset.filter(lambda x: x< 3)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S_kIwbhrmKs"
      },
      "source": [
        "**`take()`**: Will let to take a look at just a few items from a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM1I8edyrhF3",
        "outputId": "82deda47-7bfe-4078-ec66-1dee9c12b907"
      },
      "source": [
        "for item in dataset.take(3):\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjR3xTmlr1N9"
      },
      "source": [
        "## Shuffling the Data\n",
        "`shuffle()`\n",
        "\n",
        "Start by filling up a buffer with a first items of the sauce dataset. Then it pull out randomly from the buffer, and constantly replacing it fresh ones, until it has iterated entire dataset. After which it just randomly picks up from the buffer, until the buffer itself is empty.\n",
        "\n",
        "<mark>We must specify the buffer size and make it large enough, or else the shuffling will not be very effective</mark>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX3OK8BKrx1h",
        "outputId": "f7d7d4f0-f789-416b-cc2d-338b072cb82b"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=36).batch(7)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1 2 4 5 3 7 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 9 0 1 2 4 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([3 7 6 8 9 0 1], shape=(7,), dtype=int64)\n",
            "tf.Tensor([2 4 5 3 7 6 8], shape=(7,), dtype=int64)\n",
            "tf.Tensor([9 0], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTWVO_XN-7B8"
      },
      "source": [
        "### Interleaving lines from multiple files\n",
        "Let's suppose we have loaded California Housing dataset and shuffled it.\n",
        "\n",
        "Then we split each set into many CSV files and also have `train_filepaths` and `test_filepaths` listing all paths to the respective splitted files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI7UUB1Gt0Gp"
      },
      "source": [
        "X_train, X_test = pd.read_csv(\"/content/sample_data/california_housing_train.csv\"),pd.read_csv(\"/content/sample_data/california_housing_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzDYMgrLAgap"
      },
      "source": [
        "X_train.shape\n",
        "train_filepaths = []\n",
        "for index in np.arange(17000).reshape((1700, 10)):\n",
        "  path = \"/content/housing/train/train_{}.csv\".format(index[0])\n",
        "  X_train.iloc[index].to_csv(path, na_rep='NULL', index=False)\n",
        "  train_filepaths.append(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8CtED3xBPz1"
      },
      "source": [
        "X_test.shape\n",
        "test_filepaths = []\n",
        "for index in np.arange(3000).reshape((300, 10)):\n",
        "  path = \"/content/housing/test/test_{}.csv\".format(index[0])\n",
        "  X_test.iloc[index].to_csv(path, na_rep='NULL', index=False)\n",
        "  test_filepaths.append(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXQ9Uv6aJJNK"
      },
      "source": [
        "Now, we'll create a dataset containing only these file paths:\n",
        "\n",
        "By default, `list_files()` returns a dataset that shuffles the file paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOejsz5OBR7p"
      },
      "source": [
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvI0LLBxJ_Xg"
      },
      "source": [
        "Next, we can call the `interleave()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Ft-bdhEzER"
      },
      "source": [
        "n_readers = 5\n",
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "    cycle_length=n_readers\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lcN7Rm3LXTC"
      },
      "source": [
        "This code above create a dataset that will pull five file paths from the `filepath_dataset`, and for each one it will call the function we gave (a lambda in our case). \n",
        "\n",
        "This dataset on interation, will cycle through these five `TextLineDatasets` reading one line at a time from each until alll datasets are out of items, then get the next set of five file paths and repeating the cycle until all paths are done.\n",
        "\n",
        "> ðŸŸ¢ <mark>For interleaving to work best, it is best considered to have files of identical length</mark>; otherwise the ends of the longest file will not be interleaved.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqjmzUMPKZpB",
        "outputId": "69338bc7-b3fb-416c-df4c-06e3a4e79973"
      },
      "source": [
        "for line in dataset.take(5):\n",
        "  print(line.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'-117.09,32.79,20.0,2183.0,534.0,999.0,496.0,2.8631,169700.0'\n",
            "b'-121.46,38.55,52.0,2094.0,463.0,1364.0,407.0,1.2235,68500.0'\n",
            "b'-117.35,34.09,14.0,5983.0,1224.0,3255.0,1150.0,2.5902,111500.0'\n",
            "b'-118.06,34.07,30.0,2308.0,674.0,3034.0,691.0,2.3929,184400.0'\n",
            "b'-119.34,36.31,14.0,1635.0,422.0,870.0,399.0,2.7,88900.0'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yDrBqvbM_IE"
      },
      "source": [
        "Ok looks good so far. But these are byte strings for which we need to parse them and scale the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv-hDB5WNHPQ"
      },
      "source": [
        "## Preprocessing the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwjgKgsSM1Jg"
      },
      "source": [
        "# mean and scale of each feature in the training set\n",
        "X_mean, X_std = tf.constant([X_train[col].mean() for col in X_train.columns[:-1]]), tf.constant([X_train[col].std() for col in X_train.columns[:-1]]) \n",
        "n_inputs = 8\n",
        "\n",
        "def preprocess(line):\n",
        "  defaults = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "  fields = tf.io.decode_csv(line, record_defaults=defaults)\n",
        "  x = tf.stack(fields[:-1])\n",
        "  y = tf.stack(fields[-1:])\n",
        "  return (x - X_mean)/ X_std, y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hNRhEhRTvZl"
      },
      "source": [
        "- The `preprocessing()` method accepts one csv line and start by parsing it by the use of `tf.io.decode_csv` which accept the line to parse, and the default value for each column in the CSV file. \n",
        "\n",
        "  The `defaults` array tells the TF not only the default value as well as the type. The last value is an empty array of type `tf.float32` as the the default value for the Target column, i.e., there is no default value, which will raise an exception it it encounters a missing value.\n",
        "\n",
        "- Next, we use `tf.stack()` to convert the scalar tensors returned by `decode_csv()` to 1D tensor arrays.\n",
        "- Finally we scale the input features by substracting the feature means and then dividing by the feature standard devaition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOpy2VJkZr0j",
        "outputId": "c40c2513-41ae-4a43-8946-38abed329739"
      },
      "source": [
        "preprocess(b'-117.09,32.79,20.0,2183.0,534.0,999.0,496.0,2.8631,169700.0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 1.2328726 , -1.3265201 , -0.6824022 , -0.21131904, -0.01283709,\n",
              "        -0.3751125 , -0.01358042, -0.53479785], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([169700.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgXBpYVyfTmN"
      },
      "source": [
        "## Putting everything Together\n",
        "Let's put everything inside a helper function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piGH4WZSe_vI"
      },
      "source": [
        "def csv_reader_dataset(filepaths, repeat=1, n_readers=5, \n",
        "                       n_read_threads=None, shuffle_buffer_Size=10000,\n",
        "                       n_parse_threads=5, batch_size=32):\n",
        "  dataset = tf.data.Dataset.list_files(filepaths)\n",
        "  dataset = dataset.interleave(\n",
        "      lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "      cycle_length=n_readers,\n",
        "      num_parallel_calls=n_read_threads\n",
        "  )\n",
        "  dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "  dataset = dataset.shuffle(shuffle_buffer_Size).repeat(repeat)\n",
        "  return dataset.batch(batch_size).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPZaaX2SYquF"
      },
      "source": [
        "## Prefetching\n",
        "Prefetching make sure that while our training algorithm is working on one batch, the dataset will already be working in prallel on getting the next batch ready.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKSMJKY9mdyO"
      },
      "source": [
        "## Using the Dataset with tf.keras\n",
        "Now, we can use the `csv_reader_dataset()` method to create datsets for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPD20ar-Xm5h"
      },
      "source": [
        "train_set = csv_reader_dataset(train_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFBfKvaxngWv"
      },
      "source": [
        "We can now just build the model and train using this datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfh2quChnOAi",
        "outputId": "4dc3f3ea-a7dc-4a80-ce33-cdbcf37cefd8"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(8,)),\n",
        "    keras.layers.Dense(100, activation='selu', kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(30, activation='selu', kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(10, activation='selu', kernel_initializer='he_normal'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.Adam(clipvalue=1.0),\n",
        "              loss='mean_squared_error'\n",
        "              )\n",
        "model.fit(train_set, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 56400796873.7261\n",
            "Epoch 2/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 53093408583.5647\n",
            "Epoch 3/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 38846154160.2702\n",
            "Epoch 4/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 21626058728.9456\n",
            "Epoch 5/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 16831467387.4371\n",
            "Epoch 6/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 14712653011.3321\n",
            "Epoch 7/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 12084396616.0450\n",
            "Epoch 8/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 9361468076.9081\n",
            "Epoch 9/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 6774109708.4878\n",
            "Epoch 10/10\n",
            "532/532 [==============================] - 2s 2ms/step - loss: 5697598855.4447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f357266e850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X01oO7j0pDIr",
        "outputId": "f5d5c262-6bab-4a02-c5f8-2402cfc90fce"
      },
      "source": [
        "model.evaluate(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94/94 [==============================] - 0s 880us/step - loss: 3693629184.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3693629184.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGlsDsRTpnon",
        "outputId": "364a4e3a-7628-42e7-8c0f-85fe30ffc459"
      },
      "source": [
        "new_set = test_set.take(3).map(lambda X, y: X) # pretend we have 3 new instances\n",
        "model.predict(new_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[215925.94 ],\n",
              "       [ 82064.44 ],\n",
              "       [225029.   ],\n",
              "       [ 71812.34 ],\n",
              "       [175324.67 ],\n",
              "       [ 86000.54 ],\n",
              "       [ 50630.04 ],\n",
              "       [170799.67 ],\n",
              "       [146458.31 ],\n",
              "       [171650.22 ],\n",
              "       [172896.1  ],\n",
              "       [ 84453.24 ],\n",
              "       [157570.78 ],\n",
              "       [367245.94 ],\n",
              "       [140307.11 ],\n",
              "       [162180.53 ],\n",
              "       [379032.06 ],\n",
              "       [234662.23 ],\n",
              "       [117128.08 ],\n",
              "       [306170.1  ],\n",
              "       [ 97702.76 ],\n",
              "       [220105.28 ],\n",
              "       [207660.23 ],\n",
              "       [382949.22 ],\n",
              "       [177859.62 ],\n",
              "       [117736.375],\n",
              "       [248225.8  ],\n",
              "       [235437.73 ],\n",
              "       [200412.02 ],\n",
              "       [293587.38 ],\n",
              "       [135386.12 ],\n",
              "       [126311.32 ],\n",
              "       [166202.89 ],\n",
              "       [297741.2  ],\n",
              "       [ 80680.92 ],\n",
              "       [216568.31 ],\n",
              "       [117326.96 ],\n",
              "       [ 75087.89 ],\n",
              "       [147954.94 ],\n",
              "       [171751.1  ],\n",
              "       [ 99163.31 ],\n",
              "       [226181.95 ],\n",
              "       [164042.94 ],\n",
              "       [118487.555],\n",
              "       [112824.055],\n",
              "       [199234.33 ],\n",
              "       [180697.38 ],\n",
              "       [119464.82 ],\n",
              "       [112923.11 ],\n",
              "       [253482.39 ],\n",
              "       [261645.62 ],\n",
              "       [201577.5  ],\n",
              "       [127618.375],\n",
              "       [222729.4  ],\n",
              "       [196261.67 ],\n",
              "       [325973.2  ],\n",
              "       [106833.1  ],\n",
              "       [219755.25 ],\n",
              "       [244791.77 ],\n",
              "       [286270.84 ],\n",
              "       [360461.8  ],\n",
              "       [157667.   ],\n",
              "       [ 53288.824],\n",
              "       [270466.84 ],\n",
              "       [296980.78 ],\n",
              "       [160040.53 ],\n",
              "       [354073.1  ],\n",
              "       [ 87643.19 ],\n",
              "       [131666.08 ],\n",
              "       [257825.12 ],\n",
              "       [205799.02 ],\n",
              "       [177020.25 ],\n",
              "       [152432.19 ],\n",
              "       [122734.586],\n",
              "       [126962.96 ],\n",
              "       [136284.38 ],\n",
              "       [244704.67 ],\n",
              "       [ 90773.83 ],\n",
              "       [229156.08 ],\n",
              "       [232335.64 ],\n",
              "       [388218.72 ],\n",
              "       [118824.92 ],\n",
              "       [249039.23 ],\n",
              "       [399437.3  ],\n",
              "       [245767.98 ],\n",
              "       [ 64407.992],\n",
              "       [ 83138.375],\n",
              "       [ 96599.17 ],\n",
              "       [173929.62 ],\n",
              "       [360151.4  ],\n",
              "       [313648.22 ],\n",
              "       [229543.36 ],\n",
              "       [386622.34 ],\n",
              "       [360909.7  ],\n",
              "       [288013.56 ],\n",
              "       [106631.03 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUVNyI5NYd2Z"
      },
      "source": [
        "It is even possible to create a TF Function that performs the whole training loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In-z8_Gns8GF"
      },
      "source": [
        "@tf.function\n",
        "def train(model, optimizer, loss_fn, n_epochs):\n",
        "  train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs)\n",
        "  for X_batch, y_batch in train_set:\n",
        "    with tf.GradientTape as tape:\n",
        "      y_pred = model(X_batch)\n",
        "      main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "      loss = tf.add_n([main_loss] + model.losses)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradient(zip(grads, model.trainaible_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNgg6de5Zpbr"
      },
      "source": [
        "The CSV files are easy to handle with, but they are not effective and do not support complex data structure or (such as images, audio, video). \n",
        "\n",
        "In that case, it is preferrable to use TFRecords instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgy8LfbFaA6n"
      },
      "source": [
        "# The TFRecord Format\n",
        "Binary format that comprises of sequences of binary records of varying sizes. Each record is comprised of a length, a CRC checksum to check that the length was not corrupted, then the data, and finally a CRC checksum for the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V2e2xVpZdRh"
      },
      "source": [
        "# Creating a TFRecord\n",
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
        "  f.write(b\"This is a simple line of Text\")\n",
        "  f.write(b\"And this second line of Text\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH18x8ZTbmWW"
      },
      "source": [
        "**`tf.data.TFRecordDataset`**: To read a TFRecord."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgkvhbBQblyf",
        "outputId": "5fa08e13-e3ce-48b6-c7b6-d852ba754d2e"
      },
      "source": [
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is a simple line of Text', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this second line of Text', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d58hEpVvcNZl"
      },
      "source": [
        ">ðŸŸ¢You can make `TFRecordDataset` read multiple files in parallel and interleave their records by setting `num_parallel_calls`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuXJdId2cfKY"
      },
      "source": [
        "## Compressed TFRecord Files\n",
        "We can compress a TFRecord file by setting the `options` argument like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJnNPMvnb_eq"
      },
      "source": [
        "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
        "  f.write(b\"This is a compressed record\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFYqygGRdK3q"
      },
      "source": [
        "Specify the compression type when reading a compressed TFRecord."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX3OYVW-dEYT"
      },
      "source": [
        "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"], compression_type=\"GZIP\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a5AvPTTddi1"
      },
      "source": [
        "## A Brief Introduction to Protocol Buffers\n",
        "We can use any binary record format to create records But TFRecord files usually contain serialized protocol buffers (alos called *protobufs*). It is an efficient binary format developed at Google back in 2001, and the open sourced in 2008. \n",
        "\n",
        "This is defined using a synatx like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9YfIWuxdcOb"
      },
      "source": [
        "# Not to be executed | For illustration purpose\n",
        "syntax= \"proto3\";\n",
        "message Person {\n",
        "    string name = 1;\n",
        "    int32 id = 2;\n",
        "    repeated string email = 3;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni428cvBd4VL"
      },
      "source": [
        "The defination says, we are going to use Version 3 of Protocolbuf format. Then we go on specifiying the message `Person` which may contain a `name` of type `string`, and `id` of type `int32`, and zero or more `email`. The numbers corresponging to each field are called field identifiers, using to storing binary representation of that particular record.\n",
        "\n",
        "After this we save this to a *.proto* file and compile it using `protoc` (a protobuf compiler) to generatte access class in any language we may want. \n",
        "\n",
        "For now, the definations we will have already been compiled and access class are going to be part of TensorFlow, so we have to focus only on use of protobuf access class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5iOnDBHfDVv"
      },
      "source": [
        "# For illustration purpose only | Don't execute\n",
        "\n",
        "from person_pb2 import Person # import the generated access class\n",
        "person = Person(name=\"AL\", id=123, email=[\"a@b.com\"])\n",
        "print(person)\n",
        "\n",
        "person.name # display the field\n",
        "person.name = \"Anurag\" # modify the field\n",
        "person.email[0] # repeated fields are accessed like array\n",
        "person.email.append(\"c@d.com\") # add an email address\n",
        "\n",
        "# serialize the object to byte string\n",
        "s = person.SerializeToString() \n",
        "\n",
        "# create a new Person\n",
        "person2 = Person() \n",
        "person2.ParseFromString(s) # parse the byte string (27 bytes long)\n",
        "person == person2 # now they are equal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtaQC4TamHCI"
      },
      "source": [
        "We could save the serialized Person Object to a TFRecord file, and then use it as a dataset as we have seen before. \n",
        "\n",
        "However, the functions used here are not TF operations and hence can not be put inside a TF Function. Fortunately, TensorFlow does include special protobuf definitions for which it provides parsing operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CocVwnN1msaw"
      },
      "source": [
        "## TensorFlow Protobufs\n",
        "<mark>The main protobuf typically used in a TFRecord file is the `Example` protobuf</mark>, which represent one instance in a Dataset. It contains a list of named features, where each feature can either be a list of byte strings, a list of floats, or a list of integers.\n",
        "\n",
        "The protobuf definitions goes like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwUrH5CkfMqc"
      },
      "source": [
        "# For illustration purpose | don't execute\n",
        "syntax = \"proto3\";\n",
        "message BytesList { repeated bytes value = 1; }\n",
        "message FloatList { repeated float value = 1 [packed = true]; }\n",
        "message Int64List { repeated int64 value = 1 [packed = true]; }\n",
        "\n",
        "message Feature {\n",
        "    oneof kind {\n",
        "        BytesList bytes_list = 1;\n",
        "        FloatList float_list = 2;\n",
        "        Int64List int64_list = 3;\n",
        "    }\n",
        "};\n",
        "\n",
        "message Features {map<string, Feature> feature = 1; };\n",
        "message Example { Features feature = 1; };"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZccFmYMpoJO"
      },
      "source": [
        "A bit of explaination might be required. \n",
        "\n",
        "- `[packed = true]` used for repeated numerical values, for more efficient encoding.\n",
        "- A `Feature` object can contain either a `BytesList` or `FloatList` or `Int64List` message/object.\n",
        "- A `Features` containes a dictionary that maps a feature name to the corresponding feature value.\n",
        "- An `Example` contains only a `Features` object.\n",
        "\n",
        "Here is how you create an `Example` object using `tf.train.Example` storing the same `Person` as earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LII8fHFTvRJP"
      },
      "source": [
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Feature, Features, Example\n",
        "\n",
        "person_example = Example(\n",
        "    features= Features(\n",
        "        feature={\n",
        "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alic\"])),\n",
        "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
        "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", \n",
        "                                                          b\"c@d.com\"]))\n",
        "        }\n",
        "    )\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVC_DK7TwnlX"
      },
      "source": [
        "Now we can write the resulting data to TFRecord by serializing it using `SerializeToString()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uPc1immwVOj"
      },
      "source": [
        "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
        "  f.write(person_example.SerializeToString())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTIQhTxvxkx7"
      },
      "source": [
        "Now that we have a nice TFRecord file containing a serialized `Example`, let's try to load it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNFoA_I7xtAa"
      },
      "source": [
        "## Loading and Parsing Example\n",
        "To load the serialized `Example` protobuf in TFRecord, we will use `tf.data.TFRecordDataset`, and we will parse each `Example` using `tf.io.parse_single_example()`.\n",
        "\n",
        "This are TF opeations and hence can be written in TF Functions.\n",
        "\n",
        "**`tf.io.parse_single_example()`**: <mark>Requires two arguments, namely, a string scalar tensor containing the serialized data, and a description of each feature.</mark>\n",
        "\n",
        "The description is a dictionary with the key being the feature name, and value is either a object of `tf.io.FixedLenFeature` (which describes feature's shape, type, and default value) or `tf.io.VarLenFeature` (indicating only the type). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFtQCkDTw-pi"
      },
      "source": [
        "feature_description = {\n",
        "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
        "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    \"emails\": tf.io.VarLenFeature(tf.string)\n",
        "}\n",
        "\n",
        "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
        "  parsed_example = tf.io.parse_single_example(serialized_example, \n",
        "                                              feature_description)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcPRhxgHHQaN"
      },
      "source": [
        "<mark>The fixed length features are parsed as regular tensors, but the variable-length features are parsed as sparse tensors.</mark>\n",
        "\n",
        "We can use `tf.sparse.to_dense()` to convert sparse tensor to dense tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyi3gUrs1Vhj",
        "outputId": "07096a56-a2c0-4d84-d96a-54a640ef6782"
      },
      "source": [
        "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npQlrjGVHvkc",
        "outputId": "802591d3-5c81-43ba-bc02-3ebf0b18430a"
      },
      "source": [
        "# But in this case it is just simpler to access its values.\n",
        "parsed_example[\"emails\"].values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpIkMFnvI4RW"
      },
      "source": [
        "**A `BytesList` can contain any binary data we may want, including any serialized object.**\n",
        "\n",
        "- Use `tf.io.encode_jpeg()` to encode an image using the JPEG format to put in Binary data. Later on when we want to read the image back, we can use `tf.io.decode_jpeg()` or `tf.io.decode_image()`.\n",
        "- For tensors use `tf.io.serialize_tensor()` to get byte string, and then to parse the TFRecord using `tf.io.parse_tensor()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSFLXlXbH1V-"
      },
      "source": [
        "# Parsing in batch\n",
        "dataset = tf.data.TFRecordDataset(\"my_contacts.tfrecord\").batch(10)\n",
        "for serialized_example in dataset:\n",
        "  parsed_example = tf.io.parse_example(serialized_example,\n",
        "                                       feature_description)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBTs2vU2Kkjv"
      },
      "source": [
        "## Handling Lists of Lists Using the `SequenceExample` Protobuf\n",
        "The definition of `SequenceExample` Protobuf goes like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVmxf_I-KD6O"
      },
      "source": [
        "# For illustration purpose only | Don't Execute\n",
        "message FeatureList { repeated Feature feature = 1; };\n",
        "message FeatureLists { map<string, FeatureList> feature_list = 1; };\n",
        "message SequenceExample {\n",
        "    Features context = 1;\n",
        "    FeatureLists feature_lists = 2;\n",
        "};"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FURtVmhFNVep"
      },
      "source": [
        "Explanation might be required:\n",
        "- A `SequenceExample` contains:\n",
        "  \n",
        "  -  `Features` object for contexual data and (on parsing a dictionary)\n",
        "  -  `FeatureLists` object that contains one or more named `FeatureList` objects. (on parsing a dictionary)\n",
        "      - Each `FeatureList` contains a **list of `Feature`** object which as you may guess can either a `BytesList` or `FloatList` or `Int64List` message/object.\n",
        "\n",
        "For example where this might be useful and give a good idea of its purpose.\n",
        "\n",
        "Suppose An article, We can divide it's various content and save it in `SequenceExample` like this: \n",
        "- The `context` can be like the *author*, the *date* etc.\n",
        "- A `FeatureList` named \"*`content`*\" and other one being \"*`comment`*\".\n",
        "- Each `Feature` would then be a sentence. Remember a `FeatureList` is **a list of `Feature`**.\n",
        "\n",
        "Parsing can be done with the help of \n",
        "- `tf.io.parse_single_sequence_example()`: when parsing single example\n",
        "- `tf.io.parse_sequence_example()`: for batch.\n",
        "\n",
        "<mark>If the feature lists contain sequences of varying sizes, we might want to convert them to ragged tensors</mark>, using `tf.RaggedTensor.from_sparse()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e72Kx9a8V61j"
      },
      "source": [
        "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
        "    serialized_sequence_example, \n",
        "    context_feature_descriptions,\n",
        "    sequence_feature_descriptions\n",
        ")\n",
        "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9wJPYRnWwUF"
      },
      "source": [
        "The next step becomes to prepare the data so that we can feed it to Neural Network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxjo1f8QamdI"
      },
      "source": [
        "# Preprocessing the Input Features\n",
        "We can preprocess data generally at three points during the whole process:\n",
        "- Ahead of time when preparing the data usually when we have data that can fit in memory. Using tools like Numpy, Scikit-Learn.\n",
        "- On the fly when loading it with the Data APU (e.g. using the `map()` method). Suitable for huge amount of Data.\n",
        "- Or including a preprocessing layer directly in our model.\n",
        "\n",
        "Let's look at the last option.\n",
        "\n",
        "\n",
        "For example, here we implemented a standardization layer using a `Lambda` layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ00GVmRW4Ep"
      },
      "source": [
        "means = np.mean(X_train, axis=0, keepdims=True)\n",
        "stds = np.mean(X_train, axis=0, keepdims=True)\n",
        "eps = keras.backend.epsilon() # smoothing term\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.lambda(lambda inputs: (inputs - mean) / (std + eps)),\n",
        "    #... other layers\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU2BCFFcc8qm"
      },
      "source": [
        "This looks hacky. Instead we might want to have a cutom layer itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KitDJZLbdEhc"
      },
      "source": [
        "class Standardization(keras.layers.Layer):\n",
        "  def adapt(self, data_sample):\n",
        "    self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
        "    self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
        "  def call(self, inputs):\n",
        "    return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuFGjDsPeYjq"
      },
      "source": [
        "But before we can use this layer, we require it to adapt it to dataset i.e., initiliazing the variables by calling its `adapt()` method and passing it a data sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOxxPBwmd5U6"
      },
      "source": [
        "std_layer = Standardization()\n",
        "std_layer.adapt(data_sample)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEXzzq2AfTO5"
      },
      "source": [
        "Soon keras will be going to provide a Standardization layer by default, using `keras.layers.Normalization`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4c14U6hfglK"
      },
      "source": [
        "## Encoding Categorical Features Using One-Hot Vectors\n",
        "One hot encoding is frequently used for encoding Categorical features. Here we take categorical feature *`ocean_proximity`* from famous California Housing Dataset.\n",
        "\n",
        "**For this, we first need to map each category to its index (0 to 4), which can be done using a lookup table:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5jAfKK_d7yi"
      },
      "source": [
        "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR_OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
        "indices = tf.range(len(vocab), dtype=tf.int64)\n",
        "\n",
        "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
        "num_oov_buckets = 2\n",
        "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_NBKQI3nIsx"
      },
      "source": [
        "What's written here can be explained like this:\n",
        "- We defined the *vocabulary*: list of all possible categories.\n",
        "- Then created a tensor containing the corresponding indices.\n",
        "- After which we created an intializer for lookup table, passing it the vocabulary, and the indices.\n",
        "- Finally, we created the lookup table, passing it the initializer created in last step and the number of <mark>***out-of-vocabulary***</mark> bucets. If we look up a category that does not exist in the vocabulary, the lookup table will compute a hash of this category and use it to assign the unknown category to one of the oov buckets. (which in current example starts with 5 and 6).\n",
        "\n",
        "\n",
        "**Why oov buckets?**\n",
        "\n",
        "If the amount of categories is large and the dataset is itself large as well, we may find getting every category listed inconvenient. For this we define vocab based on Data Sample and some oov buckets for the expected unknown categories we might find during training.\n",
        "\n",
        "Let's try experimenting with this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGN8FdhPq-U2",
        "outputId": "5cfc3f90-3aa0-4511-df86-3d32e646365d"
      },
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nly4T7H-rewH",
        "outputId": "7a60666c-8c13-472b-ce50-718d9b35981c"
      },
      "source": [
        "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab)+num_oov_buckets)\n",
        "cat_one_hot"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RWSqOr2AUWi"
      },
      "source": [
        "All this might be good for quite a small size ($<$10) of vocabulary. But if the vocabulary is large ($>$50), we use ***embeddings*** instead for more efficient econding. Otherwise in between check for both options and see which one works best for your case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iiZQxb6Anpp"
      },
      "source": [
        "## Encoding Categorical Features Using Embeddings\n",
        "<mark>An embedding is a trainable dense vector that represents a category.</mark>\n",
        "\n",
        "So let's say the vetor `[0.341, 098]` represent a category. <mark>The number of dimension is a hyperprameter you can tweak.</mark>\n",
        "\n",
        "The training makes the the embeddings a better representations of category as the model makes better predictions and gradient descent performs the adjustments to these vector (which are initially initlaized randomly). This is called ***representation learning***.\n",
        "\n",
        "Let's look how they work by implementing is manually and then by using keras.\n",
        "\n",
        "**First off, we need to create an *embedding matrix* containing each category's embedding, initialized randomly.**\n",
        "- This matrix will be of dimension `(no_category + no_oov_buckets, embedding dimension)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIq_-aXowim5"
      },
      "source": [
        "embedding_dim = 2\n",
        "num_oov_buckets = 2\n",
        "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
        "embedding_matrix = tf.Variable(embed_init)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBNcPWrFN4dF"
      },
      "source": [
        "<mark>As a rule of thumn embeddings typically have 10 to 300 dimensions</mark>, depending on the task and the vocabulary size.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6Ihah19OXW_",
        "outputId": "2a9ece98-3ea4-4260-f7b6-cd6737431072"
      },
      "source": [
        "embedding_matrix"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
              "array([[0.54719055, 0.23783255],\n",
              "       [0.13420415, 0.09093356],\n",
              "       [0.21342385, 0.9513116 ],\n",
              "       [0.36454678, 0.91104376],\n",
              "       [0.89632404, 0.5941464 ],\n",
              "       [0.48755026, 0.57294965],\n",
              "       [0.37951005, 0.816712  ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvXwKK2pOmd_"
      },
      "source": [
        "Now let's create the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCDKX5MZOZDp",
        "outputId": "23dd90c4-e2d2-4867-ddb2-63b8ec678eff"
      },
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5WR7FBtOuhj",
        "outputId": "09e5ad45-a7e4-4383-8f62-ea1c5dd54aff"
      },
      "source": [
        "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[0.36454678, 0.91104376],\n",
              "       [0.48755026, 0.57294965],\n",
              "       [0.13420415, 0.09093356],\n",
              "       [0.13420415, 0.09093356]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JersRHUPJgv"
      },
      "source": [
        "`tf.nn.embedding_lookup()` does nothing but looks in the rows in the embedding matrix at the given indices.\n",
        "\n",
        "Keras provides a `keras.layers.Embedding` layer that handles the embedding matrix (trainable, by default) which does the same work as the `embedding_lookup` if not trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPj2YhxpO2fW",
        "outputId": "e28d6700-0322-449c-cea3-00046a32d593"
      },
      "source": [
        "embedding = keras.layers.Embedding(input_dim=len(vocab)+ num_oov_buckets,\n",
        "                                   output_dim=embedding_dim)\n",
        "embedding(cat_indices)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[-0.00481472,  0.0458963 ],\n",
              "       [-0.04767811,  0.03206981],\n",
              "       [-0.01720978,  0.01737824],\n",
              "       [-0.01720978,  0.01737824]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvoTvmQzQuIx"
      },
      "source": [
        "Putting this layer inside a model, will make it learn embeddings for categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5AcqoxnQgT3"
      },
      "source": [
        "regular_inputs = keras.layers.Input(shape=(8))\n",
        "categories = keras.layers.Input(shape=(), dtype=tf.string)\n",
        "\n",
        "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
        "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
        "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
        "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
        "\n",
        "model = keras.models.Model(inputs=[regular_inputs, categories],\n",
        "                          outputs=[outputs])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvcbt2zMvuH1"
      },
      "source": [
        "The model presented here features a input of 8 numerical features, and a categorical input. \n",
        "\n",
        "For embedding to work, we put a `Lambda` layer to look up each category's index and then on the following line we look for the embeddings for the indices. \n",
        "\n",
        "Next we contatenate the input and the embeddings and fed it to a Neural Network whihc for now is just a single Neuron.\n",
        "\n",
        "---\n",
        "When the `keras.layers.TextVectorization` layer is available, we can replace it with `Lambda` layer, eliminating the need for the looking table code too. The Layer will take care of creating the looking table by adapting to the data (using the `adapt()` method)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiInPcRjzyvP"
      },
      "source": [
        ">ðŸ”µ One-hot encoding followed by a `Dense` layer (with no activation function and biases) is equivalent to an `Embedding` layer as the weight matrix acts as embedding matrix. \n",
        ">\n",
        "> Hence, **It would be wasteful to use more embedding dimensions than the number of units in the layer that follows the `Embedding` layer.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU6BW1oU0dlC"
      },
      "source": [
        "## Keras Preprocessing Layers\n",
        "The TensorFlow community is working on a new set standard Keras Preprocesing layers. This new API will not only include layers like `keras.layers.Normalization` and `keras.layers.TextVectorization` but layers like `keras.layers.Discretization` which can <mark>chop continuos data into different bins and encode each bin as a one-hot vector.</mark>\n",
        "\n",
        ">ðŸŸ  The `Discritization` layer will be nondifferentiable (and indeed doesn't need to be differentiable as during training the **Preprocessing layer will be frozen**). The layer should only be used at the start of the model. This also means that,\n",
        "> \n",
        "> **`Embedding` layer should not be used directly in a cutom preprocessing layer**, as the `Embedding` layer requires training and as said earlier, during training a Preprocessing layer is Frozen.\n",
        "\n",
        "We will also be able to chain Preprocessing operations with the help of `PreprocessingStage`. If this pipeline contains nondifferentiable preprocessing layer, then it can only be used at the start of the model. The pipeline will adapt to a data sample and then will be able to use like a regular Layer.\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm9oNhf1vJ9q",
        "outputId": "223cedf9-b239-43da-b80f-2d899d26e038"
      },
      "source": [
        "normalization = keras.layers.Normalization()\n",
        "discretization = keras.layers.Discretization([...])\n",
        "pipeline = keras.layers.PreprocessingStage([normalization, discretization])\n",
        "pipeline.adapt(data_sample)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object `keras.layers.Normalization` not found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYaAcoAEKa1D"
      },
      "source": [
        "# TF Transform\n",
        "If preprocessing is computationally expensive, then handling it before rather than on fly might give us better performance.\n",
        "\n",
        "Also, if the dataset is small enough to git in RAM, then we can use its `cache()` method. But if it's too large, then tools like Apache Beam or Spark will be the need of hour.\n",
        "\n",
        "But this also creates the probelem of writing preprocessing code for the platform it is targetted / deployed to. And this may lead to subtle differences between the preprocessing operations performed on different platforms of your deployed model depending on the code. Also adding the maintenance headache and being errorprone.\n",
        "\n",
        "Another way is to add Preprocessing layers when we deploy the models to the already trained model from the preprocessed data by Apache Beam or Spark. \n",
        "\n",
        "But by far the Best way out there probably is to use TF Transform, which is part of TensorFlow Extended (TFX), an end-to-end platform for productionizing TensorFlow models. \n",
        "\n",
        "You can then create your preprocesing function, by using TF Transform Function and even TF Functions for scaling, bucketizing, and much more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDIRA-W8G62r"
      },
      "source": [
        "import tensorflow_transform as tft\n",
        "\n",
        "def preprocess(inputs):\n",
        "  \"\"\"\n",
        "  Pretending we just had two features\n",
        "  \"\"\"\n",
        "  median_age = inputs[\"housing_median_age\"]\n",
        "  ocean_proximity = inputs[\"ocean_proximity\"]\n",
        "  standardized_age = tft.scale_to_z_score(median_age)\n",
        "  ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
        "  return {\n",
        "      \"standardized_median_age\": standardized_age,\n",
        "      \"ocean_proximity_id\": ocean_proximity_id\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKS4iP8a7QYs"
      },
      "source": [
        "TF Transform will also generate an equivalent TensorFlow Function that we can plug into the model we deploy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDUrd_At7bb1"
      },
      "source": [
        "# The TensorFlow Datasets (TFDS) Project\n",
        "The TensorFlow Datasets project makes it very easy to download common datasets.\n",
        "\n",
        "TFDS doesn't come preinstalled with TF, so get it (you know the black magic). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204,
          "referenced_widgets": [
            "5f1de6cc217f4d06a5cf78d4f0901867",
            "ee2696246fcc40de8e5835fd4c39c21b",
            "0458f79b63804cedb85fc7c39382bcf8",
            "43c666d82e094e8ca5e92f516499efa3",
            "6b36b132663d4d76ad156c8a0ce6cfd0",
            "14922ad8d602457ca598d8115b10e72a",
            "bfc22d6ba6d647169b8a91f2ac8eeb62",
            "3f7174645c774868b0452809fba9f511"
          ]
        },
        "id": "8XRBxgpJvRbI",
        "outputId": "0626dc3a-2e93-4882-b878-b0b0f7eaf55e"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset = tfds.load(name=\"mnist\")\n",
        "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f1de6cc217f4d06a5cf78d4f0901867",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptioâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd_G3N-E8oI_"
      },
      "source": [
        "We can then apply any transformation to this datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0O0CWnBvWop"
      },
      "source": [
        "mnist_train = mnist_train.shuffle(10000).batch(32).prefetch(1)\n",
        "for item in mnist_train:\n",
        "  images = item[\"image\"]\n",
        "  labels = item[\"label\"]\n",
        "  [...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esupVFyw9LGq"
      },
      "source": [
        "Keras exepects each item in the dataset to be a tuple containing two elements (one for features, other for labels). The `load()` can itself do this for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Q9nkpHIJ-3"
      },
      "source": [
        "dataset = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
        "mnist_train = dataset[\"train\"].prefetch(1)\n",
        "model = keras.models.Sequential([...])\n",
        "model.compile(loss=\"sparse_categorical_entropy\",\n",
        "              optimizer=\"sgd\")\n",
        "model.fit(mnist_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}